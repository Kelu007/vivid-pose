<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Vivid Pose">
  <meta property="og:title" content="Vivid Pose"/>
  <meta property="og:description" content="VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/video_t1.png" />
  <meta property="og:image:width" content="2412"/>
  <meta property="og:image:height" content="1394"/> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Image-to-Video">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://Kelu007.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://Kelu007.github.io/vivid-pose">
            VividPose
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://Kelu007.github.io">Qilin Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://jiangzhengkai.github.io/">Zhengkai Jiang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://chmxu.github.io/">Chengming Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=xiK4nFUAAAAJ&hl=zh-CN">Yabiao Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Lh6fVE8AAAAJ&hl=en">Xinyi Zhang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=vpQEyBcAAAAJ&hl=en">Yun Cao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=KPava2YAAAAJ&hl=zh-CN">Weijian Cao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=fqte5H4AAAAJ&hl=zh-CN">Chengjie Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.co.uk/citations?user=Vg54TcsAAAAJ&hl=en">Yanwei Fu</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Fudan University,</span>
            <span class="author-block"><sup>2</sup>Tencent</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2405.18156v1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Kelu007/VividPose"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        VividPose turns static images into high-fidelity and temporally consistent animation videos.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Human image animation involves generating a video from a static image by following a specified pose sequence. Current approaches typically adopt a multi-stage pipeline that separately learns appearance and motion, which often leads to appearance degradation and temporal inconsistencies. To address these issues, we propose VividPose, an innovative end-to-end pipeline based on Stable Video Diffusion (SVD) that ensures superior temporal stability. To enhance the retention of human identity, we propose an identity-aware appearance controller that integrates additional facial information without compromising other appearance details such as clothing texture and background. This approach ensures that the generated videos maintain high fidelity to the identity of human subject, preserving key facial features across various poses. To accommodate diverse human body shapes and hand movements, we introduce a geometry-aware pose controller that utilizes both dense rendering maps from SMPL-X and sparse skeleton maps. This enables accurate alignment of pose and shape in the generated videos, providing a robust framework capable of handling a wide range of body shapes and dynamic hand movements. Extensive qualitative and quantitative experiments on the UBCFashion and TikTok benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, VividPose exhibits superior generalization capabilities on our proposed in-the-wild dataset. Codes and models will be available.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ End abstract. -->

<!-- Youtube video -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/framework.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
          <b>Overview of VividPose.</b> The Denoising UNet (i.e., SVD), consists of Spatial-Attention, Cross-Attention, Temporal-Conv, and Temporal-Attention blocks. We utilize ReferenceNet to encode multi-scale features from the reference image, which are then injected into the denoising UNet via spatial self-attention. We also use CLIP to encode high-level features and ID Controller (i.e., ArcFace) to encode face identity features. These two features are injected via decoupled cross-attention. The compositional sequences consist of a skeleton map sequence extracted by DWPose and a rendering map sequence extracted by SMPLer-X. These sequences are initially encoded by the Pose Controller and then fused with noisy video frame latents. Furthermore, the reference image latent, generated by the VAE encoder, is concatenated with the noisy latents.
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Make Human Images Vivid</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/real_human_demo1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/cartoon_demo1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/real_human_demo2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/cartoon_demo2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="video5" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/real_human_demo3.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video6">
          <video poster="" id="video6" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/cartoon_demo3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
      <h2 class="content has-text-centered">
        VividPose demonstrates excellent performance on both real-world human images and cartoon images. Please note that cartoons are an unseen domain during training.
      </h2>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Make Human Images Fashionable</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_3.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_4.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="video5" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_5.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video6">
          <video poster="" id="video6" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/fashion_comp_6.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
      <h2 class="content has-text-centered">
        VividPose demonstrates excellent performance on UBCFashion dataset.
      </h2>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Make Human Images Dance</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_3.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_4.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="video5" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_5.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video6">
          <video poster="" id="video6" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/tiktok_comp_6.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
      <h2 class="content has-text-centered">
        VividPose demonstrates excellent performance on TikTok dataset.
      </h2>
    </div>
  </div>
</section>
<!-- End video carousel -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024vividpose,
      title={VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation}, 
      author={Qilin Wang and Zhengkai Jiang and Chengming Xu and Jiangning Zhang and Yabiao Wang and Xinyi Zhang and Yun Cao and Weijian Cao and Chengjie Wang and Yanwei Fu},
      journal={arXiv preprint arXiv:2405.18156v1},
      website={https://Kelu007.github.io/vivid-pose/},
      year={2024}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2405.18156v1" class="external-link" disabled>
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Kelu007/VividPose" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was adapted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  bulmaCarousel.attach('#results-carousel', {
      slidesToScroll: 1,
      slidesToShow: 1,
      infinite: true,
      autoplay: false,
  });
</script>

</body>
</html>
